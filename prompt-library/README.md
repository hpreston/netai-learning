# System Prompts
A "prompt" is the input sent to the LLM. This includes every question or answer in a chat, as well as a special kind of prompt, the "System Prompt".  

System prompts are used to provide instructions to the LLM about the interaction that is taking place. These are used to create the "persona" or "role" the LLM will have.  The same LLM can be used to create an "Expert network engineer focusing on helping you configure and troubleshoot your network" or a "Pirate first mate who shares stories of battles, booty, and glory".  The only difference between the two would be the "System Prompt".  

System prompts also provide constraints on the types of questions and interactions that the LLM should engage in.  It can give background information and reference details. It can provide context on a particular problem statement, or "tools" that the the LLM has access to.  It can even provide examples for how the LLM should repond to questions.  

In short, the "System Prompt" is a significant way LLMs can be tuned and prepared to be useful for different use cases.  

In this folder, I'll share different "System Prompts" that I've used for different types of AI use cases and projects.  